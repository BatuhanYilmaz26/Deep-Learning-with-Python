{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning for timeseries\n",
    "#### Different kinds of timeseries tasks\n",
    "A **timeseries** can be any data obtained via measurements at regular intervals, like the daily price of a stock, the hourly electricity consumption of a city, or the weekly sales of a store. Timeseries are everywhere, whether we’re looking at natural phenomena (like seismic activity, the evolution of fish populations in a river, or the weather at a location) or human activity patterns (like visitors to a website, a country’s GDP, or credit card transactions). Unlike the types of data you’ve encountered so far, working with timeseries involves understanding the dynamics of a system—its periodic cycles, how it trends over time, its regular regime and its sudden spikes. <br>\n",
    "By far, the most common timeseries-related task is **forecasting**: predicting what will happen next in a series. Forecast electricity consumption a few hours in advance so you can anticipate demand; forecast revenue a few months in advance so you can plan your budget; forecast the weather a few days in advance so you can plan your schedule. Forecasting is what this chapter focuses on. But there’s actually a wide range of other things you can do with timeseries:\n",
    "- **Classification**—Assign one or more categorical labels to a timeseries. For instance, given the timeseries of the activity of a visitor on a website, classify whether the visitor is a bot or a human.\n",
    "- **Event detection**—Identify the occurrence of a specific expected event within a continuous data stream. A particularly useful application is “hotword detection,” where a model monitors an audio stream and detects utterances like “Ok Google” or “Hey Alexa.”\n",
    "- **Anomaly detection**—Detect anything unusual happening within a continuous datastream. Unusual activity on your corporate network? Might be an attacker. Unusual readings on a manufacturing line? Time for a human to go take a look. Anomaly detection is typically done via unsupervised learning, because you often don’t know what kind of anomaly you’re looking for, so you can’t train on specific anomaly examples.\n",
    "\n",
    "When working with timeseries, you’ll encounter a wide range of domain-specific data representation techniques. For instance, you have likely already heard about the **Fourier transform**, which consists of expressing a series of values in terms of a superposition of waves of different frequencies. The Fourier transform can be highly valuable when preprocessing any data that is primarily characterized by its cycles and oscillations (like sound, the vibrations of the frame of a skyscraper, or your brain waves). In the context of deep learning, Fourier analysis (or the related Mel-frequency analysis) and other domain-specific representations can be useful as a form of feature engineering, a way to prepare data before training a model on it, to make the job of the model easier. However, we won’t cover these techniques in these pages; we will instead focus on the modeling part. <br>\n",
    "In this chapter, you’ll learn about recurrent neural networks (RNNs) and how to apply them to timeseries forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A temperature-forecasting example\n",
    "Throughout this chapter, all of our code examples will target a single problem: predicting the temperature 24 hours in the future, given a timeseries of hourly measurements of quantities such as atmospheric pressure and humidity, recorded over the recent past by a set of sensors on the roof of a building. As you will see, it’s a fairly challenging problem! <br>\n",
    "We’ll use this temperature-forecasting task to highlight what makes timeseries data fundamentally different from the kinds of datasets you’ve encountered so far. You’ll see that densely connected networks and convolutional networks aren’t well-equipped to deal with this kind of dataset, while a different kind of machine learning technique—**recurrent neural networks (RNNs)**—really shines on this type of problem.\n",
    "\n",
    "We’ll work with a weather timeseries dataset recorded at the weather station at the Max Planck Institute for Biogeochemistry in Jena, Germany. In this dataset, 14 different quantities (such as temperature, pressure, humidity, wind direction, and so on) were recorded every 10 minutes over several years. The original data goes back to 2003, but the subset of the data we’ll download is limited to 2009–2016. <br> Let’s start by downloading and uncompressing the data:\n",
    "\n",
    "```python\n",
    "!wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
    "!unzip jena_climate_2009_2016.csv.zip\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s look at the data.\n",
    "\n",
    "##### Inspecting the data of the Jena weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
      "420451\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "fname = os.path.join(\"jena_climate_2009_2016.csv\")\n",
    "\n",
    "with open(fname) as f:\n",
    "    data = f.read()\n",
    "\n",
    "lines = data.split(\"\\n\")\n",
    "header = lines[0].split(\",\")\n",
    "lines = lines[1:]\n",
    "\n",
    "print(header)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This outputs a count of 420,551 lines of data (each line is a timestep: a record of a date and 14 weather-related values), as well as the headers above.\n",
    "\n",
    "Now, convert all 420,551 lines of data into NumPy arrays: one array for the temperature (in degrees Celsius), and another one for the rest of the data—the features we will use to predict future temperatures. Note that we discard the “Date Time” column.\n",
    "\n",
    "##### Parsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "temperature = np.zeros((len(lines),))\n",
    "raw_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(\",\")[1:]]\n",
    "    temperature[i] = values[1] # We store column 1 in the “temperature” array.\n",
    "    raw_data[i, :] = values[:] # We store all columns (including the temperature) in the “raw_data” array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting the temperature timeseries\n",
    "The chart below shows the plot of temperature (in degrees Celsius) over time. On this plot, you can clearly see the yearly periodicity of temperature—the data spans 8 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16bcc08d250>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(range(len(temperature)), temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting the first 10 days of the temperature timeseries\n",
    "The chart below shows a more narrow plot of the first 10 days of temperature data. Because the data is recorded every 10 minutes, you get 24 × 6 = 144 data points per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16bcf2f7dc0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1440), temperature[:1440])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this plot, you can see daily periodicity, especially for the last 4 days. Also note that this 10-day period must be coming from a fairly cold winter month.\n",
    "\n",
    "With our dataset, if you were trying to predict average temperature for the next month given a few months of past data, the problem would be easy, due to the reliable year scale periodicity of the data. But looking at the data over a scale of days, the temperature looks a lot more chaotic. Is this timeseries predictable at a daily scale? Let’s find out. <br>\n",
    "In all our experiments, we’ll use the first 50% of the data for training, the following 25% for validation, and the last 25% for testing. **When working with timeseries data, it’s important to use validation and test data that is more recent than the training data**, because you’re trying to predict the future given the past, not the reverse, and your validation/test splits should reflect that. Some problems happen to be considerably simpler if you reverse the time axis!\n",
    "\n",
    "##### Computing the number of samples we’ll use for each data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_samples: 210225\n",
      "num_val_samples: 105112\n",
      "num_test_samples: 105114\n"
     ]
    }
   ],
   "source": [
    "num_train_samples = int(0.5 * len(raw_data))\n",
    "num_val_samples = int(0.25 * len(raw_data))\n",
    "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
    "\n",
    "print(f\"num_train_samples: {num_train_samples}\")\n",
    "print(f\"num_val_samples: {num_val_samples}\")\n",
    "print(f\"num_test_samples: {num_test_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing the data\n",
    "The exact formulation of the problem will be as follows: given data covering the previous five days and sampled once per hour, can we predict the temperature in 24 hours?\n",
    "- First, let’s preprocess the data to a format a neural network can ingest. \n",
    "  - This is easy: the data is already numerical, so you don’t need to do any vectorization. \n",
    "  - But each timeseries in the data is on a different scale (for example, atmospheric pressure, measured in mbar, is around 1,000, while H2OC, measured in millimoles per mole, is around 3). \n",
    "  - We’ll **normalize each timeseries independently** so that they all take small values on a similar scale. \n",
    "  - We’re going to use the first 210,225 timesteps as training data, so we’ll compute the mean and standard deviation **only on this fraction of the data**.\n",
    "\n",
    "##### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = raw_data[:num_train_samples].mean(axis=0)\n",
    "raw_data -= mean\n",
    "std = raw_data[:num_train_samples].std(axis=0)\n",
    "raw_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s create a Dataset object that yields batches of data from the past five days along with a target temperature 24 hours in the future. Because the samples in the dataset are highly redundant (sample N and sample N + 1 will have most of their timesteps in common), it would be wasteful to explicitly allocate memory for every sample. Instead, we’ll generate the samples on the fly while only keeping in memory the original raw_data and temperature arrays, and nothing more. <br>\n",
    "We could easily write a Python generator to do this, but there’s a built-in dataset utility in Keras that does just that (**timeseries_dataset_from_array()**), so we can save ourselves some work by using it. You can generally use it for any kind of timeseries forecasting task.\n",
    "\n",
    "##### Understanding timeseries_dataset_from_array()\n",
    "To understand what **timeseries_dataset_from_array()** does, let’s look at a simple example. The general idea is that you provide an array of timeseries data (the data argument), and **timeseries_dataset_from_array()** gives you windows extracted from the original timeseries (we’ll call them **“sequences”**). <br>\n",
    "For example, if you use **data = [0 1 2 3 4 5 6]** and **sequence_length=3**, then **timeseries_dataset_from_array()** will generate the following samples: [0 1 2], [1 2 3], [2 3 4], [3 4 5], [4 5 6]. <br>\n",
    "You can also pass a **targets** argument (an array) to **timeseries_dataset_from_array()**. The first entry of the targets array should match the desired target for the first sequence that will be generated from the data array. So if you’re doing timeseries forecasting, targets should be the same array as data, offset by some amount. <br>\n",
    "For instance, with data = [0 1 2 3 4 5 6 …] and sequence_length=3, you could create a dataset to predict the next step in the series by passing targets = [3 4 5 6 …]. Let’s try it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "int_sequence = np.arange(10) # Generate an array of sorted integers from 0 to 9.\n",
    "dummy_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    data=int_sequence[:-3], # The sequences we generate will be sampled from [0 1 2 3 4 5 6].\n",
    "    targets=int_sequence[3:], # The target for the sequence that starts at data[N] will be data[N + 3].\n",
    "    sequence_length=3, # The sequences will be 3 steps long.\n",
    "    batch_size=2, # The sequences will be batched in batches of size 2.\n",
    ")\n",
    "\n",
    "for inputs, targets in dummy_dataset:\n",
    "    for i in range(inputs.shape[0])\n",
    "```\n",
    "\n",
    "This bit of code prints the following results:\n",
    "\n",
    "```python\n",
    "[0, 1, 2] 3\n",
    "[1, 2, 3] 4\n",
    "[2, 3, 4] 5\n",
    "[3, 4, 5] 6\n",
    "[4, 5, 6] 7\n",
    "```\n",
    "\n",
    "We’ll use **timeseries_dataset_from_array()** to instantiate three datasets: one for training, one for validation, and one for testing. <br>\n",
    "We’ll use the following parameter values:\n",
    "- **sampling_rate = 6**—Observations will be sampled at one data point per hour: we will only keep one data point out of 6.\n",
    "- **sequence_length = 120**—Observations will go back 5 days (120 hours).\n",
    "- **delay = sampling_rate * (sequence_length + 24 - 1)**—The target for a sequence will be the temperature 24 hours after the end of the sequence.\n",
    "\n",
    "When making the training dataset, we’ll pass start_index = 0 and end_index = num_train_samples to only use the first 50% of the data. For the validation dataset, we’ll pass start_index = num_train_samples and end_index = num_train_samples + num_val_samples to use the next 25% of the data. Finally, for the test dataset, we’ll pass start_index = num_train_samples + num_val_samples to use the remaining samples.\n",
    "\n",
    "##### Instantiating datasets for training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "sampling_rate = 6\n",
    "sequence_length = 120\n",
    "delay = sampling_rate * (sequence_length + 24 - 1)\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0,\n",
    "    end_index=num_train_samples\n",
    ")\n",
    "\n",
    "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples,\n",
    "    end_index=num_train_samples + num_val_samples\n",
    ")\n",
    "\n",
    "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples + num_val_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset yields a tuple (samples, targets), where samples is a batch of 256 samples, each containing 120 consecutive hours of input data, and targets is the corresponding array of 256 target temperatures. Note that the samples are randomly shuffled, so two consecutive sequences in a batch (like samples[0] and samples[1]) aren’t necessarily temporally close.\n",
    "\n",
    "##### Inspecting the output of one of our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples shape: (256, 120, 14)\n",
      "targets shape: (256,)\n"
     ]
    }
   ],
   "source": [
    "for samples, targets in train_dataset:\n",
    "    print(f\"samples shape: {samples.shape}\")\n",
    "    print(f\"targets shape: {targets.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A common-sense, non-machine learning baseline\n",
    "Before we start using black-box deep learning models to solve the temperature prediction problem, let’s try a simple, common-sense approach. It will serve as a sanity check, and it will establish a baseline that we’ll have to beat in order to demonstrate the usefulness of more-advanced machine learning models. Such common-sense baselines can be useful when you’re approaching a new problem for which there is no known solution (yet). A classic example is that of unbalanced classification tasks, where some classes are much more common than others. If your dataset contains 90% instances of class A and 10% instances of class B, then a common-sense approach to the classification task is to always predict “A” when presented with a new sample. Such a classifier is 90% accurate overall, and any learning-based approach should therefore beat this 90% score in order to demonstrate usefulness. Sometimes, such elementary baselines can prove surprisingly hard to beat. <br>\n",
    "In this case, the temperature timeseries can safely be assumed to be continuous (the temperatures tomorrow are likely to be close to the temperatures today) as well as periodical with a daily period. Thus a common-sense approach is to always predict that the temperature 24 hours from now will be equal to the temperature right now. Let’s evaluate this approach, using the mean absolute error (MAE) metric, defined as follows:\n",
    "\n",
    "```python\n",
    "np.mean(np.abs(preds - targets))\n",
    "```\n",
    "\n",
    "Here’s the evaluation loop.\n",
    "\n",
    "##### Computing the common-sense baseline MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 2.44\n",
      "Test MAE: 2.62\n"
     ]
    }
   ],
   "source": [
    "def evaluate_naive_method(dataset):\n",
    "    total_abs_err = 0.\n",
    "    samples_seen = 0\n",
    "    for samples, targets in dataset:\n",
    "        # The temperature feature is at column 1, so samples[:, -1, 1] is the last temperature measurement in the input sequence. \n",
    "        # Recall that we normalized our features, so to retrieve a temperature in degrees Celsius, we need to un-normalize it by multiplying it by the standard deviation and adding back the mean.\n",
    "        preds = samples[:, -1, 1] * std[1] + mean[1]\n",
    "        total_abs_err += np.sum(np.abs(preds - targets))\n",
    "        samples_seen += samples.shape[0]\n",
    "    return total_abs_err / samples_seen\n",
    "\n",
    "print(f\"Validation MAE: {evaluate_naive_method(val_dataset):.2f}\")\n",
    "print(f\"Test MAE: {evaluate_naive_method(test_dataset):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This common-sense baseline achieves a validation MAE of 2.44 degrees Celsius and a test MAE of 2.62 degrees Celsius. So if you always assume that the temperature 24 hours in the future will be the same as it is now, you will be off by two and a half degrees on average. It’s not too bad, but you probably won’t launch a weather forecasting service based on this heuristic. Now the game is to use your knowledge of deep learning to do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let’s try a basic machine learning model\n",
    "In the same way that it’s useful to establish a common-sense baseline before trying machine learning approaches, it’s useful to try simple, cheap machine learning models (such as small, densely connected networks) before looking into complicated and computationally expensive models such as RNNs. This is the best way to make sure any further complexity you throw at the problem is legitimate and delivers real benefits. <br>\n",
    "- The following listing shows a fully connected model that starts by flattening the data and then runs it through two **Dense** layers. \n",
    "- **Note the lack of an activation function on the last Dense layer, which is typical for a regression problem.** \n",
    "- We use **mean squared error (MSE)** as the loss, rather than MAE, because unlike MAE, it’s smooth around zero, which is a useful property for gradient descent. \n",
    "- We will monitor MAE by adding it as a metric in **compile()**.\n",
    "\n",
    "##### Training and evaluating a densely connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "819/819 [==============================] - 9s 11ms/step - loss: 13.3554 - mae: 2.8220 - val_loss: 11.5500 - val_mae: 2.6908\n",
      "Epoch 2/10\n",
      "819/819 [==============================] - 8s 10ms/step - loss: 9.3000 - mae: 2.3975 - val_loss: 16.0460 - val_mae: 3.1795\n",
      "Epoch 3/10\n",
      "819/819 [==============================] - 8s 10ms/step - loss: 8.4063 - mae: 2.2791 - val_loss: 10.7242 - val_mae: 2.6002\n",
      "Epoch 4/10\n",
      "819/819 [==============================] - 8s 10ms/step - loss: 7.8794 - mae: 2.2084 - val_loss: 11.1886 - val_mae: 2.6397\n",
      "Epoch 5/10\n",
      "819/819 [==============================] - 8s 10ms/step - loss: 7.5057 - mae: 2.1547 - val_loss: 16.7965 - val_mae: 3.2572\n",
      "Epoch 6/10\n",
      "819/819 [==============================] - 8s 10ms/step - loss: 7.2716 - mae: 2.1237 - val_loss: 10.8369 - val_mae: 2.5922\n",
      "Epoch 7/10\n",
      "819/819 [==============================] - 8s 10ms/step - loss: 7.0382 - mae: 2.0898 - val_loss: 10.6679 - val_mae: 2.5682\n",
      "Epoch 8/10\n",
      "819/819 [==============================] - 8s 10ms/step - loss: 6.8793 - mae: 2.0667 - val_loss: 10.3639 - val_mae: 2.5311\n",
      "Epoch 9/10\n",
      "819/819 [==============================] - 8s 9ms/step - loss: 6.7391 - mae: 2.0468 - val_loss: 10.8329 - val_mae: 2.5843\n",
      "Epoch 10/10\n",
      "819/819 [==============================] - 8s 9ms/step - loss: 6.6123 - mae: 2.0261 - val_loss: 10.9775 - val_mae: 2.6041\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 12.0201 - mae: 2.7328\n",
      "Test MAE: 2.73\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"jena_dense.keras\",\n",
    "                                    save_best_only=True) # We use callbacks to save the best performing model.\n",
    "]\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# Reload the best model and evaluate it on the test dataset.\n",
    "model = keras.models.load_model(\"jena_dense.keras\")\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s display the loss curves for validation and training.\n",
    "\n",
    "##### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the validation losses are close to the no-learning baseline, but not reliably. This goes to show the merit of having this baseline in the first place: it turns out to be not easy to outperform. Your common sense contains a lot of valuable information to which a machine learning model doesn’t have access. <br>\n",
    "You may wonder, if a simple, well-performing model exists to go from the data to the targets (the common-sense baseline), why doesn’t the model you’re training find it and improve on it? Well, the space of models in which you’re searching for a solution—that is, your hypothesis space—is the space of all possible two-layer networks with the configuration you defined. The common-sense heuristic is just one model among millions that can be represented in this space. It’s like looking for a needle in a haystack. Just because a good solution technically exists in your hypothesis space doesn’t mean you’ll be able to find it via gradient descent. <br>\n",
    "That’s a pretty significant limitation of machine learning in general: unless the learning algorithm is hardcoded to look for a specific kind of simple model, it can sometimes fail to find a simple solution to a simple problem. That’s why leveraging good feature engineering and relevant architecture priors is essential: you need to precisely tell your model what it should be looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let’s try a 1D convolutional model\n",
    "Speaking of leveraging the right architecture priors, since our input sequences feature daily cycles, perhaps a convolutional model could work. A temporal convnet could reuse the same representations across different days, much like a spatial convnet can reuse the same representations across different locations in an image. <br>You already know about the **Conv2D** and **SeparableConv2D** layers, which see their inputs through small windows that swipe across 2D grids. There are also 1D and even 3D versions of these layers: **Conv1D**, **SeparableConv1D**, and **Conv3D**. The **Conv1D** layer relies on 1D windows that slide across input sequences, and the **Conv3D** layer relies on cubic windows that slide across input volumes. <br>\n",
    "You can thus build 1D convnets, strictly analogous to 2D convnets. They’re a great fit for any sequence data that follows the translation invariance assumption (meaning that if you slide a window over the sequence, the content of the window should follow the same properties independently of the location of the window).\n",
    "\n",
    "Let’s try one on our temperature-forecasting problem. We’ll pick an initial window length of 24, so that we look at 24 hours of data at a time (one cycle). As we downsample the sequences (via **MaxPooling1D** layers), we’ll reduce the window size accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "819/819 [==============================] - 26s 30ms/step - loss: 21.1474 - mae: 3.6123 - val_loss: 17.3127 - val_mae: 3.3306\n",
      "Epoch 2/10\n",
      "819/819 [==============================] - 24s 29ms/step - loss: 14.7919 - mae: 3.0487 - val_loss: 14.8383 - val_mae: 3.0484\n",
      "Epoch 3/10\n",
      "819/819 [==============================] - 24s 29ms/step - loss: 13.2410 - mae: 2.8815 - val_loss: 13.3847 - val_mae: 2.8783\n",
      "Epoch 4/10\n",
      "819/819 [==============================] - 24s 29ms/step - loss: 12.4773 - mae: 2.7965 - val_loss: 13.7586 - val_mae: 2.9048\n",
      "Epoch 5/10\n",
      "819/819 [==============================] - 24s 29ms/step - loss: 11.9414 - mae: 2.7333 - val_loss: 13.3461 - val_mae: 2.8793\n",
      "Epoch 6/10\n",
      "819/819 [==============================] - 25s 30ms/step - loss: 11.5036 - mae: 2.6841 - val_loss: 18.2027 - val_mae: 3.3867\n",
      "Epoch 7/10\n",
      "819/819 [==============================] - 24s 29ms/step - loss: 11.1722 - mae: 2.6469 - val_loss: 13.5649 - val_mae: 2.8907\n",
      "Epoch 8/10\n",
      "819/819 [==============================] - 25s 30ms/step - loss: 10.8778 - mae: 2.6099 - val_loss: 15.2423 - val_mae: 3.0751\n",
      "Epoch 9/10\n",
      "819/819 [==============================] - 25s 30ms/step - loss: 10.6397 - mae: 2.5843 - val_loss: 15.7185 - val_mae: 3.1132\n",
      "Epoch 10/10\n",
      "819/819 [==============================] - 24s 30ms/step - loss: 10.3723 - mae: 2.5508 - val_loss: 13.5275 - val_mae: 2.8932\n",
      "405/405 [==============================] - 5s 11ms/step - loss: 14.8711 - mae: 3.0603\n",
      "Test MAE: 3.06\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.Conv1D(8, 24, activation=\"relu\",)(inputs)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(8, 12, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(8, 6, activation=\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"jena_conv.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"jena_conv.keras\")\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the training and validation curves shown above. <br>\n",
    "As it turns out, this model performs even **worse** than the densely connected one, only achieving a validation MAE of about 2.9 degrees, far from the common-sense baseline. What went wrong here? Two things:\n",
    "- First, weather data doesn’t quite respect the translation invariance assumption. While the data does feature daily cycles, data from a morning follows different properties than data from an evening or from the middle of the night. Weather data is only translation-invariant for a very specific timescale.\n",
    "- Second, order in our data matters—a lot. The recent past is far more informative for predicting the next day’s temperature than data from five days ago. A 1D convnet is not able to leverage this fact. In particular, our max pooling and global average pooling layers are largely destroying order information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A first recurrent baseline\n",
    "Neither the fully connected approach nor the convolutional approach did well, but that doesn’t mean machine learning isn’t applicable to this problem. The densely connected approach first flattened the timeseries, which removed the notion of time from the input data. The convolutional approach treated every segment of the data in the same way, even applying pooling, which destroyed order information. Let’s instead look at the data as what it is: a sequence, where causality and order matter. <br>\n",
    "There’s a family of neural network architectures designed specifically for this use case: **recurrent neural networks**. Among them, the **Long Short Term Memory (LSTM)** layer has long been very popular. We’ll see in a minute how these models work, but let’s start by giving the **LSTM** layer a try.\n",
    "\n",
    "##### A simple LSTM-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "819/819 [==============================] - 53s 61ms/step - loss: 43.5366 - mae: 4.8255 - val_loss: 12.9326 - val_mae: 2.7322\n",
      "Epoch 2/10\n",
      "819/819 [==============================] - 51s 62ms/step - loss: 11.3092 - mae: 2.6045 - val_loss: 9.8349 - val_mae: 2.4394\n",
      "Epoch 3/10\n",
      "819/819 [==============================] - 51s 62ms/step - loss: 10.0085 - mae: 2.4650 - val_loss: 10.0591 - val_mae: 2.4528\n",
      "Epoch 4/10\n",
      "819/819 [==============================] - 49s 60ms/step - loss: 9.6286 - mae: 2.4155 - val_loss: 10.0788 - val_mae: 2.4443\n",
      "Epoch 5/10\n",
      "819/819 [==============================] - 49s 59ms/step - loss: 9.2305 - mae: 2.3663 - val_loss: 10.0169 - val_mae: 2.4315\n",
      "Epoch 6/10\n",
      "819/819 [==============================] - 48s 59ms/step - loss: 8.8853 - mae: 2.3240 - val_loss: 9.9979 - val_mae: 2.4338\n",
      "Epoch 7/10\n",
      "819/819 [==============================] - 48s 58ms/step - loss: 8.6445 - mae: 2.2951 - val_loss: 10.2956 - val_mae: 2.4575\n",
      "Epoch 8/10\n",
      "819/819 [==============================] - 49s 59ms/step - loss: 8.4586 - mae: 2.2738 - val_loss: 10.4370 - val_mae: 2.5045\n",
      "Epoch 9/10\n",
      "819/819 [==============================] - 48s 59ms/step - loss: 8.2472 - mae: 2.2455 - val_loss: 10.0639 - val_mae: 2.4548\n",
      "Epoch 10/10\n",
      "819/819 [==============================] - 48s 59ms/step - loss: 8.1117 - mae: 2.2277 - val_loss: 10.1726 - val_mae: 2.4795\n",
      "405/405 [==============================] - 11s 25ms/step - loss: 11.5100 - mae: 2.6395\n",
      "Test MAE: 2.64\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.LSTM(16)(inputs)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"jena_lstm.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"jena_lstm.keras\")\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! We achieve a validation MAE as low as 2.36 degrees and a test MAE of 2.55 degrees. The LSTM-based model can finally beat the common-sense baseline (albeit just by a bit, for now), demonstrating the value of machine learning on this task. <br> But why did the LSTM model perform markedly better than the densely connected one or the convnet? And how can we further refine the model? To answer this, let’s take a closer look at recurrent neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding recurrent neural networks\n",
    "A major characteristic of all neural networks you’ve seen so far, such as densely connected networks and convnets, is that **they have no memory**. Each input shown to them is **processed independently**, with no state kept between inputs. With such networks, in order to process a sequence or a temporal series of data points, you have to show the entire sequence to the network at once: turn it into a single data point. For instance, this is what we did in the densely connected network example: we flattened our five days of data into a single large vector and processed it in one go. Such networks are called **feedforward networks**. <br>\n",
    "In contrast, as you’re reading the present sentence, you’re processing it word by word—or rather, eye saccade by eye saccade—while keeping memories of what came before; this gives you a fluid representation of the meaning conveyed by this sentence.\n",
    "\n",
    "Biological intelligence processes information incrementally while maintaining an internal model of what it’s processing, **built from past information and constantly updated as new information comes in**. <br>\n",
    "A **recurrent neural network (RNN)** adopts the same principle, albeit in an extremely simplified version: it processes sequences by iterating through the sequence elements and maintaining a state that contains information relative to what it has seen so far. In effect, an *RNN** is a type of neural network that has an internal loop (see figure 10.6).\n",
    "\n",
    "![](./images/10.6.png)\n",
    "\n",
    "The state of the **RNN** is reset between processing two different, independent sequences (such as two samples in a batch), so you still consider one sequence to be a single data point: a single input to the network. What changes is that this data point is no longer processed in a single step; rather, the network internally loops over sequence elements. <br>\n",
    "To make these notions of **loop** and **state** clear, let’s implement the forward pass of a toy RNN. This RNN takes as input a sequence of vectors, which we’ll encode as a rank-2 tensor of size (timesteps, input_features). It loops over timesteps, and at each timestep, it considers its current state at t and the input at t (of shape (input_features,), and combines them to obtain the output at t. We’ll then set the state for the next step to be this previous output. For the first timestep, the previous output isn’t defined; hence, there is no current state. So we’ll initialize the state as an all-zero vector called the initial state of the network. <br>\n",
    "In pseudocode, this is the RNN. <br>\n",
    "**Pseudocode RNN**\n",
    "\n",
    "```python\n",
    "state_t = 0 # The state at t\n",
    "for input_t in input_sequence: # Iterates over sequence elements\n",
    "output_t = f(input_t, state_t)\n",
    "state_t = output_t # The previous output becomes the state for the next iteration.\n",
    "```\n",
    "\n",
    "You can even flesh out the function f: the transformation of the input and state into an output will be parameterized by two matrices, W and U, and a bias vector. It’s similar to the transformation operated by a densely connected layer in a feedforward network.\n",
    "\n",
    "**More-detailed pseudocode for the RNN**\n",
    "\n",
    "```python\n",
    "state_t = 0\n",
    "for input_t in input_sequence:\n",
    "output_t = activation(dot(W, input_t) + dot(U, state_t) + b)\n",
    "state_t = output_t\n",
    "```\n",
    "\n",
    "To make these notions absolutely unambiguous, let’s write a naive NumPy implementation of the forward pass of the simple RNN.\n",
    "\n",
    "##### NumPy implementation of a simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 100 # Number of timesteps in the input sequence\n",
    "input_features = 32 # Dimensionality of the input feature space\n",
    "output_features = 64 # Dimensionality of the output feature space\n",
    "\n",
    "inputs = np.random.random((timesteps, input_features)) # Input data: random noise for the sake of the example\n",
    "state_t = np.zeros((output_features,)) # Initial state: an all-zero vector\n",
    "# Create random weight matrices\n",
    "W = np.random.random((output_features, input_features))\n",
    "U = np.random.random((output_features, output_features))\n",
    "b = np.random.random((output_features,))\n",
    "successive_outputs = []\n",
    "for input_t in inputs: # input_t is a vector of shape (input_features,)\n",
    "    # Combine the input with the current state (the previous output) to obtain the current output.\n",
    "    # We use tanh to add non-linearity (we could use any other activation function).\n",
    "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
    "    successive_outputs.append(output_t) # Stores this output in a list\n",
    "    state_t = output_t # Updates the state of the network for the next timestep\n",
    "final_output_sequence = np.stack(successive_outputs, axis=0) # The final output is a rank-2 tensor of shape(timesteps, output_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s easy enough. In summary, an RNN is a for loop that reuses quantities computed during the previous iteration of the loop, nothing more. Of course, there are many different RNNs fitting this definition that you could build—this example is one of the simplest RNN formulations. RNNs are characterized by their step function, such as the following function in this case (see figure 10.7).\n",
    "\n",
    "```python\n",
    "output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
    "```\n",
    "\n",
    "![](./images/10.7.png)\n",
    "\n",
    "> ***NOTE*** In this example, the final output is a rank-2 tensor of shape (timesteps, output_features), where each timestep is the output of the loop at time t. Each timestep t in the output tensor contains information about timesteps 0 to t in the input sequence—about the entire past. For this reason, in many cases, you don’t need this full sequence of outputs; you just need the last output (output_t at the end of the loop), because it already contains information about the entire sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A recurrent layer in Keras\n",
    "The process we just naively implemented in NumPy corresponds to an actual Keras layer—the **SimpleRNN** layer. <br>\n",
    "- There is one minor difference: **SimpleRNN** processes batches of sequences, like all other Keras layers, not a single sequence as in the NumPy example. \n",
    "- This means it takes inputs of shape **(batch_size, timesteps, input_features)**, rather than **(timesteps, input_features)**. \n",
    "- When specifying the shape argument of the initial **Input()**, note that you can set the timesteps entry to None, which enables your network to process sequences of arbitrary length.\n",
    "\n",
    "##### An RNN layer that can process sequences of any length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 14\n",
    "inputs = keras.Input(shape=(None, num_features))\n",
    "outputs = layers.SimpleRNN(16)(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is especially useful if your model is meant to process sequences of variable length. However, if all of your sequences have the same length, I recommend specifying a complete input shape, since it enables model.summary() to display output length information, which is always nice, and it can unlock some performance optimizations(see the “Note on RNN runtime performance” sidebar a little later in this chapter). <br>\n",
    "All recurrent layers in Keras (**SimpleRNN**, **LSTM**, and **GRU**) can be run in two different modes: \n",
    "- they can return either **full sequences of successive outputs for each timestep** (a rank-3 tensor of shape **(batch_size, timesteps, output_features)**) or \n",
    "- return only the **last output for each input sequence** (a rank-2 tensor of shape **(batch_size, output_features)**).\n",
    "\n",
    "These two modes are controlled by the **return_sequences** constructor argument. <br>Let’s look at an example that uses SimpleRNN and returns only the output at the last timestep.\n",
    "\n",
    "##### An RNN layer that returns only its last output step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16)\n"
     ]
    }
   ],
   "source": [
    "num_features = 14\n",
    "steps = 120\n",
    "inputs = keras.Input(shape=(steps, num_features))\n",
    "outputs = layers.SimpleRNN(16, return_sequences=False)(inputs) # Note that return_sequences=False is the default.\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example returns the full state sequence.\n",
    "\n",
    "##### An RNN layer that returns its full output sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 120, 16)\n"
     ]
    }
   ],
   "source": [
    "num_features = 14\n",
    "steps = 120\n",
    "inputs = keras.Input(shape=(steps, num_features))\n",
    "outputs = layers.SimpleRNN(16, return_sequences=True)(inputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s sometimes useful to stack several recurrent layers one after the other in order to increase the representational power of a network. In such a setup, you have to get **all of the intermediate layers to return a full sequence of outputs.**\n",
    "\n",
    "##### Stacking RNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(steps, num_features))\n",
    "x = layers.SimpleRNN(16, return_sequences=True)(inputs)\n",
    "x = layers.SimpleRNN(16, return_sequences=True)(x)\n",
    "outputs = layers.SimpleRNN(16)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, you’ll rarely work with the **SimpleRNN** layer. It’s generally too simplistic to be of real use. In particular, **SimpleRNN** has a major issue: although it should theoretically be able to retain at time t information about inputs seen many timesteps before, such long-term dependencies prove impossible to learn in practice. This is due to the **vanishing gradient** problem, an effect that is similar to what is observed with non-recurrent networks (feedforward networks) that are many layers deep: as you keep adding layers to a network, the network eventually becomes untrainable. The theoretical reasons for this effect were studied by Hochreiter, Schmidhuber, and Bengio in the early 1990s. <br>\n",
    "Thankfully, **SimpleRNN** isn’t the only recurrent layer available in Keras. There are two others, **LSTM** and **GRU**, which were designed to address these issues.\n",
    "\n",
    "Let’s consider the **LSTM** layer. The underlying **Long Short-Term Memory (LSTM)** algorithm was developed by Hochreiter and Schmidhuber in 1997;4 it was the culmination of their research on the **vanishing gradient** problem. <br>\n",
    "This layer is a variant of the **SimpleRNN** layer you already know about; it adds a way to carry information across many timesteps. Imagine a conveyor belt running parallel to the sequence you’re processing. Information from the sequence can jump onto the conveyor belt at any point, be transported to a later timestep, and jump off, intact, when you need it. This is essentially what **LSTM** does: **it saves information for later, thus preventing older signals from gradually vanishing during processing.** This should remind you of residual connections, which you learned about in chapter 9: it’s pretty much the same idea.\n",
    "\n",
    "To understand this process in detail, let’s start from the **SimpleRNN** cell (see figure 10.8). Because you’ll have a lot of weight matrices, index the W and U matrices in the cell, with the letter o (Wo and Uo) for output.\n",
    "\n",
    "![](./images/10.8.png)\n",
    "\n",
    "Let’s add to this picture an additional data flow that carries information across timesteps. Call its values at different timesteps **c_t**, where C stands for **carry**. This information will have the following impact on the cell: it will be combined with the input connection and the recurrent connection (via a dense transformation: a dot product with a weight matrix followed by a bias add and the application of an activation function), and it will affect the state being sent to the next timestep (via an activation function and a multiplication operation). Conceptually, the carry dataflow is a way to modulate the next output and the next state (see figure 10.9). Simple so far.\n",
    "\n",
    "![](./images/10.9.png)\n",
    "\n",
    "Now the subtlety—the way the next value of the carry dataflow is computed. It involves three distinct transformations. All three have the form of a **SimpleRNN** cell:\n",
    "\n",
    "```python\n",
    "y = activation(dot(state_t, U) + dot(input_t, W) + b)\n",
    "```\n",
    "\n",
    "But all three transformations have their own weight matrices, which we’ll index with the letters i, f, and k. Here’s what we have so far (it may seem a bit arbitrary, but bear with me).\n",
    "\n",
    "##### Pseudocode details of the LSTM architecture (1/2)\n",
    "\n",
    "```python\n",
    "output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(c_t, Vo) + bo)\n",
    "i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)\n",
    "f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)\n",
    "k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)\n",
    "```\n",
    "We obtain the new carry state (the next c_t) by combining i_t, f_t, and k_t.\n",
    "\n",
    "##### Pseudocode details of the LSTM architecture (2/2)\n",
    "\n",
    "```python\n",
    "c_t+1 = i_t * k_t + c_t * f_t\n",
    "```\n",
    "\n",
    "Add this as shown in figure 10.10, and that’s it. Not so complicated—merely a tad complex.\n",
    "\n",
    "![](./images/10.10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced use of recurrent neural networks\n",
    "- **Recurrent dropout**—This is a variant of dropout, used to fight overfitting in recurrent layers.\n",
    "- **Stacking recurrent layers**—This increases the representational power of the model (at the cost of higher computational loads).\n",
    "- **Bidirectional recurrent layers**—These present the same information to a recurrent network in different ways, increasing accuracy and mitigating forgetting issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using recurrent dropout to fight overfitting\n",
    "Let’s go back to the LSTM-based model we used in section 10.2.5—our first model able to beat the common-sense baseline. If you look at the training and validation curves (figure 10.5), it’s evident that the model is quickly overfitting, despite only having very few units: the training and validation losses start to diverge considerably after a few epochs. You’re already familiar with a classic technique for fighting this phenomenon: **dropout**, which randomly zeros out input units of a layer in order to break happenstance correlations in the training data that the layer is exposed to. But how to correctly apply dropout in recurrent networks isn’t a trivial question. <br>\n",
    "It has long been known that **applying dropout before a recurrent layer hinders learning rather than helping with regularization**. In 2016, Yarin Gal, as part of his PhD thesis on Bayesian deep learning, determined the proper way to use **dropout with a recurrent network**: the same dropout mask (the same pattern of dropped units) should be applied at every timestep, instead of using a dropout mask that varies randomly from timestep to timestep. What’s more, in order to regularize the representations formed by the recurrent gates of layers such as **GRU** and **LSTM**, a temporally constant dropout mask should be applied to the inner recurrent activations of the layer (a recurrent dropout mask). Using the same dropout mask at every timestep allows the network to properly propagate its learning error through time; a temporally random dropout mask would disrupt this error signal and be harmful to the learning process. <br>\n",
    "Yarin Gal did his research using Keras and helped build this mechanism directly into Keras recurrent layers. Every recurrent layer in Keras has two dropout-related arguments: **dropout**, a float specifying the dropout rate for input units of the layer, and **recurrent_dropout**, specifying the dropout rate of the recurrent units. Let’s add **recurrent dropout** to the **LSTM** layer of our first LSTM example and see how doing so impacts overfitting. <br>\n",
    "Thanks to dropout, we won’t need to rely as much on network size for regularization, so we’ll use an LSTM layer with twice as many units, which should, hopefully, be more expressive (without dropout, this network would have started overfitting right away—try it). Because networks being regularized with dropout always take much longer to fully converge, we’ll train the model for five times as many epochs.\n",
    "\n",
    "##### Training and evaluating a dropout-regularized LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "819/819 [==============================] - 139s 165ms/step - loss: 27.5805 - mae: 3.8773 - val_loss: 9.7764 - val_mae: 2.4227\n",
      "Epoch 2/50\n",
      "819/819 [==============================] - 128s 157ms/step - loss: 14.8315 - mae: 2.9919 - val_loss: 9.7257 - val_mae: 2.4173\n",
      "Epoch 3/50\n",
      "819/819 [==============================] - 124s 151ms/step - loss: 14.0890 - mae: 2.9086 - val_loss: 9.8778 - val_mae: 2.4449\n",
      "Epoch 4/50\n",
      "819/819 [==============================] - 132s 162ms/step - loss: 13.5086 - mae: 2.8455 - val_loss: 9.3280 - val_mae: 2.3659\n",
      "Epoch 5/50\n",
      "819/819 [==============================] - 163s 199ms/step - loss: 13.1337 - mae: 2.8080 - val_loss: 9.4471 - val_mae: 2.3880\n",
      "Epoch 6/50\n",
      "819/819 [==============================] - 159s 194ms/step - loss: 12.7502 - mae: 2.7637 - val_loss: 9.8792 - val_mae: 2.4337\n",
      "Epoch 7/50\n",
      "819/819 [==============================] - 152s 185ms/step - loss: 12.4886 - mae: 2.7331 - val_loss: 9.7251 - val_mae: 2.3966\n",
      "Epoch 8/50\n",
      "819/819 [==============================] - 157s 192ms/step - loss: 12.2265 - mae: 2.7002 - val_loss: 9.4403 - val_mae: 2.3796\n",
      "Epoch 9/50\n",
      "819/819 [==============================] - 158s 193ms/step - loss: 11.9191 - mae: 2.6720 - val_loss: 9.7134 - val_mae: 2.4083\n",
      "Epoch 10/50\n",
      "819/819 [==============================] - 163s 198ms/step - loss: 11.6510 - mae: 2.6449 - val_loss: 10.0611 - val_mae: 2.4490\n",
      "Epoch 11/50\n",
      "819/819 [==============================] - 166s 202ms/step - loss: 11.4291 - mae: 2.6200 - val_loss: 9.9723 - val_mae: 2.4399\n",
      "Epoch 12/50\n",
      "819/819 [==============================] - 163s 200ms/step - loss: 11.2547 - mae: 2.5977 - val_loss: 9.7589 - val_mae: 2.4134\n",
      "Epoch 13/50\n",
      "819/819 [==============================] - 159s 194ms/step - loss: 11.0512 - mae: 2.5762 - val_loss: 9.8315 - val_mae: 2.4234\n",
      "Epoch 14/50\n",
      "819/819 [==============================] - 162s 198ms/step - loss: 10.9274 - mae: 2.5606 - val_loss: 9.9411 - val_mae: 2.4417\n",
      "Epoch 15/50\n",
      "819/819 [==============================] - 160s 195ms/step - loss: 10.7669 - mae: 2.5427 - val_loss: 9.8969 - val_mae: 2.4398\n",
      "Epoch 16/50\n",
      "819/819 [==============================] - 162s 198ms/step - loss: 10.5999 - mae: 2.5230 - val_loss: 10.2312 - val_mae: 2.4770\n",
      "Epoch 17/50\n",
      "819/819 [==============================] - 164s 200ms/step - loss: 10.4700 - mae: 2.5094 - val_loss: 9.9790 - val_mae: 2.4459\n",
      "Epoch 18/50\n",
      "819/819 [==============================] - 163s 199ms/step - loss: 10.3834 - mae: 2.4957 - val_loss: 10.1485 - val_mae: 2.4702\n",
      "Epoch 19/50\n",
      "819/819 [==============================] - 164s 200ms/step - loss: 10.2340 - mae: 2.4783 - val_loss: 10.3038 - val_mae: 2.4890\n",
      "Epoch 20/50\n",
      "819/819 [==============================] - 166s 202ms/step - loss: 10.2050 - mae: 2.4755 - val_loss: 10.1553 - val_mae: 2.4677\n",
      "Epoch 21/50\n",
      "819/819 [==============================] - 173s 211ms/step - loss: 10.1449 - mae: 2.4635 - val_loss: 10.1524 - val_mae: 2.4655\n",
      "Epoch 22/50\n",
      "819/819 [==============================] - 168s 205ms/step - loss: 10.0885 - mae: 2.4584 - val_loss: 10.6145 - val_mae: 2.5233\n",
      "Epoch 23/50\n",
      "819/819 [==============================] - 169s 206ms/step - loss: 9.9447 - mae: 2.4411 - val_loss: 10.3097 - val_mae: 2.4882\n",
      "Epoch 24/50\n",
      "819/819 [==============================] - 169s 207ms/step - loss: 9.8997 - mae: 2.4329 - val_loss: 10.4727 - val_mae: 2.5078\n",
      "Epoch 25/50\n",
      "819/819 [==============================] - 173s 212ms/step - loss: 9.8022 - mae: 2.4226 - val_loss: 10.1865 - val_mae: 2.4793\n",
      "Epoch 26/50\n",
      "819/819 [==============================] - 169s 207ms/step - loss: 9.8327 - mae: 2.4228 - val_loss: 10.3786 - val_mae: 2.4969\n",
      "Epoch 27/50\n",
      "819/819 [==============================] - 164s 200ms/step - loss: 9.7847 - mae: 2.4169 - val_loss: 10.5899 - val_mae: 2.5327\n",
      "Epoch 28/50\n",
      "819/819 [==============================] - 170s 208ms/step - loss: 9.6401 - mae: 2.4042 - val_loss: 10.3297 - val_mae: 2.4897\n",
      "Epoch 29/50\n",
      "819/819 [==============================] - 168s 205ms/step - loss: 9.5865 - mae: 2.3922 - val_loss: 10.4916 - val_mae: 2.5116\n",
      "Epoch 30/50\n",
      "819/819 [==============================] - 166s 203ms/step - loss: 9.5383 - mae: 2.3858 - val_loss: 10.7788 - val_mae: 2.5479\n",
      "Epoch 31/50\n",
      "819/819 [==============================] - 166s 202ms/step - loss: 9.4807 - mae: 2.3830 - val_loss: 10.6880 - val_mae: 2.5430\n",
      "Epoch 32/50\n",
      "819/819 [==============================] - 166s 203ms/step - loss: 9.4345 - mae: 2.3736 - val_loss: 10.6724 - val_mae: 2.5426\n",
      "Epoch 33/50\n",
      "819/819 [==============================] - 166s 202ms/step - loss: 9.3844 - mae: 2.3673 - val_loss: 11.0640 - val_mae: 2.5879\n",
      "Epoch 34/50\n",
      "819/819 [==============================] - 167s 204ms/step - loss: 9.3662 - mae: 2.3628 - val_loss: 10.8042 - val_mae: 2.5636\n",
      "Epoch 35/50\n",
      "819/819 [==============================] - 166s 203ms/step - loss: 9.3222 - mae: 2.3601 - val_loss: 10.9673 - val_mae: 2.5710\n",
      "Epoch 36/50\n",
      "819/819 [==============================] - 170s 207ms/step - loss: 9.2152 - mae: 2.3458 - val_loss: 11.3084 - val_mae: 2.6110\n",
      "Epoch 37/50\n",
      "819/819 [==============================] - 170s 207ms/step - loss: 9.2045 - mae: 2.3455 - val_loss: 10.7907 - val_mae: 2.5539\n",
      "Epoch 38/50\n",
      "819/819 [==============================] - 168s 205ms/step - loss: 9.1782 - mae: 2.3385 - val_loss: 11.2955 - val_mae: 2.6017\n",
      "Epoch 39/50\n",
      "819/819 [==============================] - 167s 204ms/step - loss: 9.1978 - mae: 2.3432 - val_loss: 11.5571 - val_mae: 2.6255\n",
      "Epoch 40/50\n",
      "819/819 [==============================] - 171s 209ms/step - loss: 9.1034 - mae: 2.3333 - val_loss: 11.0159 - val_mae: 2.5602\n",
      "Epoch 41/50\n",
      "819/819 [==============================] - 178s 217ms/step - loss: 9.0958 - mae: 2.3308 - val_loss: 11.0105 - val_mae: 2.5684\n",
      "Epoch 42/50\n",
      "819/819 [==============================] - 170s 207ms/step - loss: 9.0307 - mae: 2.3234 - val_loss: 11.4306 - val_mae: 2.6131\n",
      "Epoch 43/50\n",
      "819/819 [==============================] - 173s 211ms/step - loss: 9.0266 - mae: 2.3218 - val_loss: 11.6191 - val_mae: 2.6299\n",
      "Epoch 44/50\n",
      "819/819 [==============================] - 175s 214ms/step - loss: 8.9875 - mae: 2.3173 - val_loss: 11.2715 - val_mae: 2.6001\n",
      "Epoch 45/50\n",
      "819/819 [==============================] - 177s 216ms/step - loss: 8.9899 - mae: 2.3146 - val_loss: 11.5643 - val_mae: 2.6283\n",
      "Epoch 46/50\n",
      "819/819 [==============================] - 171s 208ms/step - loss: 8.8944 - mae: 2.3060 - val_loss: 11.5961 - val_mae: 2.6325\n",
      "Epoch 47/50\n",
      "819/819 [==============================] - 173s 211ms/step - loss: 8.8300 - mae: 2.2925 - val_loss: 11.4782 - val_mae: 2.6245\n",
      "Epoch 48/50\n",
      "819/819 [==============================] - 178s 217ms/step - loss: 8.8414 - mae: 2.2953 - val_loss: 11.7065 - val_mae: 2.6492\n",
      "Epoch 49/50\n",
      "819/819 [==============================] - 175s 214ms/step - loss: 8.8155 - mae: 2.2974 - val_loss: 11.6391 - val_mae: 2.6460\n",
      "Epoch 50/50\n",
      "819/819 [==============================] - 176s 215ms/step - loss: 8.7746 - mae: 2.2894 - val_loss: 11.6790 - val_mae: 2.6483\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.LSTM(32, recurrent_dropout=0.25)(inputs)\n",
    "x = layers.Dropout(0.5)(x) # To regularize the Dense layer, we also add a Dropout layer after the LSTM.\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"jena_lstm_dropout.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=50,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/10.11.png)\n",
    "\n",
    "Figure 10.11 shows the results. Success! We’re no longer overfitting during the first 20 epochs. We achieve a validation MAE as low as 2.27 degrees (7% improvement over the no-learning baseline) and a test MAE of 2.45 degrees (6.5% improvement over the baseline). Not too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stacking recurrent layers\n",
    "Because you’re no longer overfitting but seem to have hit a performance bottleneck, you should consider increasing the capacity and expressive power of the network. Recall the description of the universal machine learning workflow: it’s generally a good idea to increase the capacity of your model until overfitting becomes the primary obstacle (assuming you’re already taking basic steps to mitigate overfitting, such as using dropout). As long as you aren’t overfitting too badly, you’re likely under capacity. <br>\n",
    "Increasing network capacity is typically done by increasing the number of units in the layers or adding more layers. Recurrent layer stacking is a classic way to build more-powerful recurrent networks: for instance, not too long ago the Google Translate algorithm was powered by a stack of seven large LSTM layers—that’s huge. <br> To stack recurrent layers on top of each other in Keras, **all intermediate layers should return their full sequence of outputs** (a rank-3 tensor) rather than their output at the last timestep. As you’ve already learned, this is done by specifying **return_sequences=True**.\n",
    "\n",
    "In the following example, we’ll try a stack of two dropout-regularized recurrent layers. For a change, we’ll use **Gated Recurrent Unit (GRU)** layers instead of **LSTM**. **GRU** is very similar to **LSTM**—you can think of it as a slightly simpler, streamlined version of the LSTM architecture. It was introduced in 2014 by Cho et al. when recurrent networks were just starting to gain interest anew in the then-tiny research community.\n",
    "\n",
    "##### Training and evaluating a dropout-regularized, stacked GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "819/819 [==============================] - 194s 231ms/step - loss: 25.9488 - mae: 3.7562 - val_loss: 9.8788 - val_mae: 2.4270\n",
      "Epoch 2/50\n",
      "819/819 [==============================] - 182s 222ms/step - loss: 13.8806 - mae: 2.8845 - val_loss: 9.0271 - val_mae: 2.3335\n",
      "Epoch 3/50\n",
      "819/819 [==============================] - 180s 220ms/step - loss: 13.0486 - mae: 2.7997 - val_loss: 8.6224 - val_mae: 2.2736\n",
      "Epoch 4/50\n",
      "819/819 [==============================] - 178s 218ms/step - loss: 12.4981 - mae: 2.7431 - val_loss: 8.6645 - val_mae: 2.2840\n",
      "Epoch 5/50\n",
      "819/819 [==============================] - 181s 221ms/step - loss: 12.0370 - mae: 2.6899 - val_loss: 8.7455 - val_mae: 2.2993\n",
      "Epoch 6/50\n",
      "819/819 [==============================] - 184s 225ms/step - loss: 11.6242 - mae: 2.6458 - val_loss: 9.5626 - val_mae: 2.4238\n",
      "Epoch 7/50\n",
      "819/819 [==============================] - 190s 231ms/step - loss: 11.2286 - mae: 2.6024 - val_loss: 8.9347 - val_mae: 2.3395\n",
      "Epoch 8/50\n",
      "819/819 [==============================] - 191s 233ms/step - loss: 10.9360 - mae: 2.5684 - val_loss: 9.0147 - val_mae: 2.3435\n",
      "Epoch 9/50\n",
      "819/819 [==============================] - 186s 227ms/step - loss: 10.6570 - mae: 2.5350 - val_loss: 8.9601 - val_mae: 2.3342\n",
      "Epoch 10/50\n",
      "819/819 [==============================] - 186s 227ms/step - loss: 10.3639 - mae: 2.5020 - val_loss: 9.1383 - val_mae: 2.3606\n",
      "Epoch 11/50\n",
      "819/819 [==============================] - 187s 229ms/step - loss: 10.0833 - mae: 2.4664 - val_loss: 9.6749 - val_mae: 2.4384\n",
      "Epoch 12/50\n",
      "819/819 [==============================] - 186s 228ms/step - loss: 9.8350 - mae: 2.4345 - val_loss: 9.6002 - val_mae: 2.4228\n",
      "Epoch 13/50\n",
      "819/819 [==============================] - 186s 227ms/step - loss: 9.5696 - mae: 2.4063 - val_loss: 9.6540 - val_mae: 2.4319\n",
      "Epoch 14/50\n",
      "819/819 [==============================] - 179s 218ms/step - loss: 9.4072 - mae: 2.3848 - val_loss: 10.1663 - val_mae: 2.4908\n",
      "Epoch 15/50\n",
      "819/819 [==============================] - 189s 231ms/step - loss: 9.2011 - mae: 2.3582 - val_loss: 9.8265 - val_mae: 2.4398\n",
      "Epoch 16/50\n",
      "819/819 [==============================] - 186s 228ms/step - loss: 9.0446 - mae: 2.3382 - val_loss: 10.7689 - val_mae: 2.5707\n",
      "Epoch 17/50\n",
      "819/819 [==============================] - 187s 229ms/step - loss: 8.8462 - mae: 2.3138 - val_loss: 10.6429 - val_mae: 2.5514\n",
      "Epoch 18/50\n",
      "819/819 [==============================] - 178s 217ms/step - loss: 8.7065 - mae: 2.2962 - val_loss: 10.6065 - val_mae: 2.5479\n",
      "Epoch 19/50\n",
      "819/819 [==============================] - 189s 231ms/step - loss: 8.6206 - mae: 2.2841 - val_loss: 10.9501 - val_mae: 2.5917\n",
      "Epoch 20/50\n",
      "819/819 [==============================] - 189s 230ms/step - loss: 8.4527 - mae: 2.2643 - val_loss: 10.5485 - val_mae: 2.5344\n",
      "Epoch 21/50\n",
      "819/819 [==============================] - 183s 223ms/step - loss: 8.3698 - mae: 2.2521 - val_loss: 11.2686 - val_mae: 2.6271\n",
      "Epoch 22/50\n",
      "819/819 [==============================] - 188s 230ms/step - loss: 8.2456 - mae: 2.2386 - val_loss: 11.3294 - val_mae: 2.6316\n",
      "Epoch 23/50\n",
      "819/819 [==============================] - 191s 233ms/step - loss: 8.2316 - mae: 2.2311 - val_loss: 11.8367 - val_mae: 2.6830\n",
      "Epoch 24/50\n",
      "819/819 [==============================] - 182s 222ms/step - loss: 8.0622 - mae: 2.2102 - val_loss: 11.6523 - val_mae: 2.6571\n",
      "Epoch 25/50\n",
      "819/819 [==============================] - 184s 225ms/step - loss: 7.9794 - mae: 2.1995 - val_loss: 12.2705 - val_mae: 2.7444\n",
      "Epoch 26/50\n",
      "819/819 [==============================] - 186s 227ms/step - loss: 7.9014 - mae: 2.1853 - val_loss: 11.6454 - val_mae: 2.6561\n",
      "Epoch 27/50\n",
      "819/819 [==============================] - 186s 227ms/step - loss: 7.7549 - mae: 2.1678 - val_loss: 11.8218 - val_mae: 2.6741\n",
      "Epoch 28/50\n",
      "819/819 [==============================] - 192s 235ms/step - loss: 7.7593 - mae: 2.1675 - val_loss: 12.3011 - val_mae: 2.7426\n",
      "Epoch 29/50\n",
      "819/819 [==============================] - 190s 232ms/step - loss: 7.7037 - mae: 2.1601 - val_loss: 12.1839 - val_mae: 2.7135\n",
      "Epoch 30/50\n",
      "819/819 [==============================] - 195s 237ms/step - loss: 7.6358 - mae: 2.1498 - val_loss: 12.2284 - val_mae: 2.7089\n",
      "Epoch 31/50\n",
      "819/819 [==============================] - 209s 255ms/step - loss: 7.5795 - mae: 2.1412 - val_loss: 12.7139 - val_mae: 2.7712\n",
      "Epoch 32/50\n",
      "819/819 [==============================] - 211s 257ms/step - loss: 7.5280 - mae: 2.1311 - val_loss: 14.1630 - val_mae: 2.9097\n",
      "Epoch 33/50\n",
      "819/819 [==============================] - 190s 232ms/step - loss: 7.4375 - mae: 2.1240 - val_loss: 12.5884 - val_mae: 2.7461\n",
      "Epoch 34/50\n",
      "819/819 [==============================] - 190s 232ms/step - loss: 7.4253 - mae: 2.1185 - val_loss: 13.8301 - val_mae: 2.8769\n",
      "Epoch 35/50\n",
      "819/819 [==============================] - 197s 241ms/step - loss: 7.3703 - mae: 2.1090 - val_loss: 12.9476 - val_mae: 2.7896\n",
      "Epoch 36/50\n",
      "819/819 [==============================] - 199s 243ms/step - loss: 7.3391 - mae: 2.1068 - val_loss: 12.5498 - val_mae: 2.7439\n",
      "Epoch 37/50\n",
      "819/819 [==============================] - 193s 235ms/step - loss: 7.2977 - mae: 2.1004 - val_loss: 13.0796 - val_mae: 2.7903\n",
      "Epoch 38/50\n",
      "819/819 [==============================] - 196s 240ms/step - loss: 7.2024 - mae: 2.0870 - val_loss: 12.5308 - val_mae: 2.7405\n",
      "Epoch 39/50\n",
      "819/819 [==============================] - 196s 240ms/step - loss: 7.1997 - mae: 2.0849 - val_loss: 12.6570 - val_mae: 2.7436\n",
      "Epoch 40/50\n",
      "819/819 [==============================] - 204s 249ms/step - loss: 7.1530 - mae: 2.0773 - val_loss: 12.5580 - val_mae: 2.7426\n",
      "Epoch 41/50\n",
      "819/819 [==============================] - 195s 238ms/step - loss: 7.1370 - mae: 2.0715 - val_loss: 12.6541 - val_mae: 2.7535\n",
      "Epoch 42/50\n",
      "819/819 [==============================] - 203s 248ms/step - loss: 7.0943 - mae: 2.0670 - val_loss: 12.8448 - val_mae: 2.7635\n",
      "Epoch 43/50\n",
      "819/819 [==============================] - 201s 245ms/step - loss: 7.0428 - mae: 2.0598 - val_loss: 13.5425 - val_mae: 2.8388\n",
      "Epoch 44/50\n",
      "819/819 [==============================] - 193s 235ms/step - loss: 7.0200 - mae: 2.0576 - val_loss: 12.5603 - val_mae: 2.7410\n",
      "Epoch 45/50\n",
      "819/819 [==============================] - 192s 234ms/step - loss: 6.9992 - mae: 2.0531 - val_loss: 12.6337 - val_mae: 2.7452\n",
      "Epoch 46/50\n",
      "819/819 [==============================] - 195s 238ms/step - loss: 6.9750 - mae: 2.0493 - val_loss: 13.7464 - val_mae: 2.8488\n",
      "Epoch 47/50\n",
      "819/819 [==============================] - 205s 250ms/step - loss: 6.9678 - mae: 2.0454 - val_loss: 12.7965 - val_mae: 2.7559\n",
      "Epoch 48/50\n",
      "819/819 [==============================] - 204s 249ms/step - loss: 6.9777 - mae: 2.0483 - val_loss: 12.9582 - val_mae: 2.7782\n",
      "Epoch 49/50\n",
      "819/819 [==============================] - 196s 239ms/step - loss: 6.9106 - mae: 2.0405 - val_loss: 13.4005 - val_mae: 2.8191\n",
      "Epoch 50/50\n",
      "819/819 [==============================] - 197s 240ms/step - loss: 6.9056 - mae: 2.0375 - val_loss: 13.0695 - val_mae: 2.7985\n",
      "405/405 [==============================] - 19s 44ms/step - loss: 9.7203 - mae: 2.4509\n",
      "Test MAE: 2.45\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.GRU(32, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
    "x = layers.GRU(32, recurrent_dropout=0.5)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=50,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 10.12 shows the results. We achieve a test MAE of 2.39 degrees (an 8.8% improvement over the baseline). You can see that the added layer does improve the results a bit, though not dramatically. You may be seeing diminishing returns from increasing network capacity at this point.\n",
    "\n",
    "![](./images/10.12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using bidirectional RNNs\n",
    "The last technique we’ll look at in this section is the **bidirectional RNN**. A **bidirectional RNN** is a common RNN variant that can offer greater performance than a regular RNN on certain tasks. It’s frequently used in **natural language processing**—you could call it the Swiss Army knife of deep learning for natural language processing. <br>\n",
    "RNNs are notably order-dependent: they process the timesteps of their input sequences in order, and shuffling or reversing the timesteps can completely change the representations the RNN extracts from the sequence. This is precisely the reason they perform well on problems where order is meaningful, such as the temperature forecasting problem. A **bidirectional RNN** exploits the order sensitivity of RNNs: it uses two regular RNNs, such as the **GRU** and **LSTM** layers you’re already familiar with, each of which processes the input sequence in one direction (chronologically and antichronologically), and then merges their representations. By processing a sequence both ways, a **bidirectional RNN** can catch patterns that may be overlooked by a unidirectional RNN. <br>\n",
    "Remarkably, the fact that the RNN layers in this section have processed sequences in chronological order (with older timesteps first) may have been an arbitrary decision. At least, it’s a decision we’ve made no attempt to question so far. Could the RNNs have performed well enough if they processed input sequences in antichronological order, for instance (with newer timesteps first)? <br> \n",
    "Let’s try this and see what happens. All you need to do is write a variant of the data generator where the input sequences are reverted along the time dimension (replace the last line with yield samples[:, ::-1, :], targets). Training the same LSTM-based model that you used in the first experiment in this section, you get the results shown in figure 10.13.\n",
    "\n",
    "![](./images/10.13.png)\n",
    "\n",
    "The reversed-order LSTM strongly underperforms even the common-sense baseline, indicating that in this case, **chronological processing is important to the success of the approach**. This makes perfect sense: the underlying LSTM layer will typically be better at remembering the recent past than the distant past, and naturally the more recent weather data points are more predictive than older data points for the problem (that’s what makes the common-sense baseline fairly strong). Thus the chronological version of the layer is bound to outperform the reversed-order version. <br>\n",
    "However, this isn’t true for many other problems, including natural language: intuitively, the importance of a word in understanding a sentence isn’t usually dependent on its position in the sentence. On text data, reversed-order processing works just as well as chronological processing—you can read text backwards just fine (try it!). Although word order does matter in understanding language, which order you use isn’t crucial. <br>\n",
    "Importantly, an RNN trained on reversed sequences will learn different representations than one trained on the original sequences, much as you would have different mental models if time flowed backward in the real world—if you lived a life where you died on your first day and were born on your last day. In machine learning, representations that are different yet useful are always worth exploiting, and the more they differ, the better: they offer a new angle from which to look at your data, capturing aspects of the data that were missed by other approaches, and thus they can help boost performance on a task. This is the intuition behind **ensembling**, a concept we’ll explore in chapter 13. <br>\n",
    "A bidirectional RNN exploits this idea to improve on the performance of chronological-order RNNs. It looks at its input sequence both ways (see figure 10.14), obtaining potentially richer representations and capturing patterns that may have been missed by the chronological-order version alone.\n",
    "\n",
    "![](./images/10.14.png)\n",
    "\n",
    "To instantiate a bidirectional RNN in Keras, you use the **Bidirectional** layer, which takes as its first argument a recurrent layer instance. **Bidirectional** creates a second, separate instance of this recurrent layer and uses one instance for processing the input sequences in chronological order and the other instance for processing the input sequences in reversed order. You can try it on our temperature-forecasting task.\n",
    "\n",
    "##### Training and evaluating a bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.Bidirectional(layers.LSTM(16))(inputs)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll find that it doesn’t perform as well as the plain LSTM layer. It’s easy to understand why: all the predictive capacity must come from the chronological half of the network, because the antichronological half is known to be severely underperforming on this task (again, because the recent past matters much more than the distant past, in this case). At the same time, the presence of the antichronological half doubles the network’s capacity and causes it to start overfitting much earlier. <br>\n",
    "However, **bidirectional RNNs are a great fit for text data**, or any other kind of data **where order matters**, yet where which order you use doesn’t matter. In fact, for a while in 2016, bidirectional LSTMs were considered the state of the art on many natural language processing tasks (before the rise of the Transformer architecture, which you will learn about in the next chapter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "- As you first learned in chapter 5, when approaching a new problem, it’s good to first establish common-sense baselines for your metric of choice. If you don’t have a baseline to beat, you can’t tell whether you’re making real progress.\n",
    "- Try simple models before expensive ones, to make sure the additional expense is justified. Sometimes a simple model will turn out to be your best option.\n",
    "- When you have data where ordering matters, and in particular for timeseries data, recurrent networks are a great fit and easily outperform models that first flatten the temporal data. The two essential RNN layers available in Keras are the LSTM layer and the GRU layer.\n",
    "- To use dropout with recurrent networks, you should use a time-constant dropout mask and recurrent dropout mask. These are built into Keras recurrent layers, so all you have to do is use the recurrent_dropout arguments of recurrent layers.\n",
    "- Stacked RNNs provide more representational power than a single RNN layer. They’re also much more expensive and thus not always worth it. Although they offer clear gains on complex problems (such as machine translation), they may not always be relevant to smaller, simpler problems."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "483abfc7fdcd927bfa336910f494643cce94b3dfa36bcded073270b8df64edb3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
