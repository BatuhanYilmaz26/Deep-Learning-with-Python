{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34Uv3tWt6wX4"
      },
      "source": [
        "#### Introduction to generative adversarial networks\n",
        "Generative adversarial networks (GANs), introduced in 2014 by Goodfellow et al.,7 are an alternative to VAEs for learning latent spaces of images. They enable the generation of fairly realistic synthetic images by forcing the generated images to be statistically almost indistinguishable from real ones. <br>\n",
        "An intuitive way to understand GANs is to imagine a forger trying to create a fake Picasso painting. At first, the forger is pretty bad at the task. He mixes some of his fakes with authentic Picassos and shows them all to an art dealer. The art dealer makes an authenticity assessment for each painting and gives the forger feedback about what makes a Picasso look like a Picasso. The forger goes back to his studio to prepare some new fakes. As time goes on, the forger becomes increasingly competent at imitating the style of Picasso, and the art dealer becomes increasingly expert at spotting fakes. <br>\n",
        "In the end, they have on their hands some excellent fake Picassos. <br>\n",
        "That’s what a GAN is: a forger network and an expert network, each being trained to best the other. As such, a GAN is made of two parts:\n",
        "- **Generator network**—Takes as input a random vector (a random point in the latent space), and decodes it into a synthetic image\n",
        "- **Discriminator network (or adversary)**—Takes as input an image (real or synthetic), and predicts whether the image came from the training set or was created by the generator network\n",
        "\n",
        "The generator network is trained to be able to fool the discriminator network, and thus it evolves toward generating increasingly realistic images as training goes on: artificial images that look indistinguishable from real ones, to the extent that it’s impossible for the discriminator network to tell the two apart (see figure 12.19). Meanwhile, the discriminator is constantly adapting to the gradually improving capabilities of the generator, setting a high bar of realism for the generated images. Once training is over, the generator is capable of turning any point in its input space into a believable image. Unlike VAEs, this latent space has fewer explicit guarantees of meaningful structure; in particular, it isn’t continuous.\n",
        "\n",
        "![](./images/12.19.png)\n",
        "\n",
        "Remarkably, a GAN is a system where the optimization minimum isn’t fixed, unlike in any other training setup you’ve encountered in this book. Normally, gradient descent consists of rolling down hills in a static loss landscape. But with a GAN, every step taken down the hill changes the entire landscape a little. It’s a dynamic system where the optimization process is seeking not a minimum, but an equilibrium between two forces. For this reason, GANs are notoriously difficult to train—getting a GAN to work requires lots of careful tuning of the model architecture and training parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoAXH4p86wX-"
      },
      "source": [
        "##### A schematic GAN implementation\n",
        "In this section, we’ll explain how to implement a GAN in Keras in its barest form. GANs are advanced, so diving deeply into the technical details of architectures like that of the StyleGAN2 that generated the images in figure 12.20 would be out of scope for this book. The specific implementation we’ll use in this demonstration is a deep convolutional GAN (DCGAN): a very basic GAN where the generator and discriminator are deep convnets.\n",
        "\n",
        "![](./images/12.20.png)\n",
        "\n",
        "We’ll train our GAN on images from the Large-scale CelebFaces Attributes dataset (known as CelebA), a dataset of 200,000 faces of celebrities (http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) To speed up training, we’ll resize the images to 64 × 64, so we’ll be learning to generate 64 × 64 images of human faces. <br>\n",
        "Schematically, the GAN looks like this:\n",
        "- A generator network maps vectors of shape (latent_dim,) to images of shape (64, 64, 3).\n",
        "- A discriminator network maps images of shape (64, 64, 3) to a binary score estimating the probability that the image is real.\n",
        "- A gan network chains the generator and the discriminator together: gan(x) = discriminator(generator(x)). Thus, this gan network maps latent space vectors to the discriminator’s assessment of the realism of these latent vectors as decoded by the generator.\n",
        "- We train the discriminator using examples of real and fake images along with “real”/“fake” labels, just as we train any regular image-classification model.\n",
        "- To train the generator, we use the gradients of the generator’s weights with regard to the loss of the gan model. This means that at every step, we move the weights of the generator in a direction that makes the discriminator more likely to classify as “real” the images decoded by the generator. In other words, we train the generator to fool the discriminator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJfoX7_46wX_"
      },
      "source": [
        "##### A bag of tricks\n",
        "The process of training GANs and tuning GAN implementations is notoriously difficult. There are a number of known tricks you should keep in mind. Like most things in deep learning, it’s more alchemy than science: these tricks are heuristics, not theorybacked guidelines. They’re supported by a level of intuitive understanding of the phenomenon at hand, and they’re known to work well empirically, although not necessarily in every context. <br>\n",
        "Here are a few of the tricks used in the implementation of the GAN generator and discriminator in this section. It isn’t an exhaustive list of GAN-related tips; you’ll find many more across the GAN literature:\n",
        "- We use strides instead of pooling for downsampling feature maps in the discriminator, just like we did in our VAE encoder.\n",
        "- We sample points from the latent space using a normal distribution (Gaussian distribution), not a uniform distribution.\n",
        "- Stochasticity is good for inducing robustness. Because GAN training results in a dynamic equilibrium, GANs are likely to get stuck in all sorts of ways. Introducing randomness during training helps prevent this. We introduce randomness by adding random noise to the labels for the discriminator.\n",
        "- Sparse gradients can hinder GAN training. In deep learning, sparsity is often a desirable property, but not in GANs. Two things can induce gradient sparsity: max pooling operations and relu activations. Instead of max pooling, we recommend using strided convolutions for downsampling, and we recommend using a LeakyReLU layer instead of a relu activation. It’s similar to relu, but it relaxes sparsity constraints by allowing small negative activation values.\n",
        "- In generated images, it’s common to see checkerboard artifacts caused by unequal coverage of the pixel space in the generator (see figure 12.21). To fix this, we use a kernel size that’s divisible by the stride size whenever we use a strided Conv2DTranspose or Conv2D in both the generator and the discriminator.\n",
        "\n",
        "![](./images/12.21.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvTakArP6wYA"
      },
      "source": [
        "##### Getting our hands on the CelebA dataset\n",
        "You can download the dataset manually from the website: http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html. If you’re using Colab, you can run the following to download the data from Google Drive and uncompress it.\n",
        "\n",
        "##### Getting the CelebA data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir celeba_gan # Create a working directory.\n",
        "!gdown --id 1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684 -O celeba_gan/data.zip # Download the compressed data using gdown (available by default in Colab; install it otherwise).\n",
        "!unzip -qq celeba_gan/data.zip -d celeba_gan # Uncompress the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XywjvVA735c"
      },
      "source": [
        "Once you’ve got the uncompressed images in a directory, you can use **image_dataset_from_directory** to turn it into a dataset. Since we just need the images—there are no labels—we’ll specify label_mode=None.\n",
        "\n",
        "##### Creating a dataset from a directory of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YfLSVoC8E1t",
        "outputId": "022b7849-348c-4fc3-fd8d-381ed8a0c282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 202599 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "dataset = keras.utils.image_dataset_from_directory(\n",
        "    \"celeba_gan\",\n",
        "    label_mode=None, # Only the images will be returned—no labels.\n",
        "    image_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    smart_resize=True) # We will resize the images to 64 × 64 by using a smart combination of cropping and resizing to preserve aspect ratio. \n",
        "    # We don’t want face proportions to get distorted!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-AJ9p0m96Th"
      },
      "source": [
        "Finally, let’s rescale the images to the [0-1] range.\n",
        "\n",
        "##### Rescaling the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AvOZqe8H99eb"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(lambda x: x / 255.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVeq-L91-AaK"
      },
      "source": [
        "You can use the following code to display a sample image.\n",
        "\n",
        "##### Displaying the first image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "amELyaC4-EGR",
        "outputId": "c427da47-432d-41d5-ba7f-2132635e6d04"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for x in dataset:\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdAS2gBC__xr"
      },
      "source": [
        "##### The discriminator\n",
        "First, we’ll develop a **discriminator** model that takes as input a candidate image(real or synthetic) and classifies it into one of two classes: “generated image” or “real image that comes from the training set.” One of the many issues that commonly arise with GANs is that the generator gets stuck with generated images that look like noise. A possible solution is to use **dropout** in the discriminator, so that’s what we will do here.\n",
        "\n",
        "##### The GAN discriminator network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zeVKBP_JAjOc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(64, 64, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2), # One dropout layer: an important trick!\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD_SnbT401Qv"
      },
      "source": [
        "Here’s the discriminator model summary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udhLVal302_O",
        "outputId": "767a8a96-4b40-40f3-8bc0-1ffcfd1ab600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 8, 128)         262272    \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 8193      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404,801\n",
            "Trainable params: 404,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ofBErm07vm"
      },
      "source": [
        "##### The generator\n",
        "Next, let’s develop a generator model that turns a vector (from the latent space—during training it will be sampled at random) into a candidate image.\n",
        "\n",
        "##### GAN generator network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cV5dyJKG1OzR"
      },
      "outputs": [],
      "source": [
        "latent_dim = 128 # The latent space will be made of 128-dimensional vectors.\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128), # Produce the same number of coefficients we had at the level of the Flatten layer in the encoder.\n",
        "        layers.Reshape((8, 8, 128)),# Revert the Flatten layer of the encoder.\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"), # Revert the Conv2D layers of the encoder.\n",
        "        layers.LeakyReLU(alpha=0.2), # We use LeakyReLU as our activation.\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"), # The output ends up with shape(28, 28, 1).\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhlPdmK52CKd"
      },
      "source": [
        "This is the generator model summary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQCCj74K2DpY",
        "outputId": "f46b98b3-de2c-4723-80a6-5df328189e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 8192)              1056768   \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 16, 16, 128)      262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 32, 32, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 64, 64, 3)         38403     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,979,651\n",
            "Trainable params: 3,979,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp4r_p5D2Lk9"
      },
      "source": [
        "##### The adversarial network\n",
        "Finally, we’ll set up the GAN, which chains the generator and the discriminator. When trained, this model will move the generator in a direction that improves its ability to fool the discriminator. This model turns latent-space points into a classification decision—“fake” or “real”—and it’s meant to be trained with labels that are always “these are real images.” So training gan will update the weights of generator in a way that makes discriminator more likely to predict “real” when looking at fake images. <br>\n",
        "To recapitulate, this is what the training loop looks like schematically. For each epoch, you do the following:\n",
        "1. Draw random points in the latent space (random noise).\n",
        "2. Generate images with generator using this random noise.\n",
        "3. Mix the generated images with real ones.\n",
        "4. Train discriminator using these mixed images, with corresponding targets: either “real” (for the real images) or “fake” (for the generated images).\n",
        "5. Draw new random points in the latent space.\n",
        "6. Train generator using these random vectors, with targets that all say “these are real images.” This updates the weights of the generator to move them toward getting the discriminator to predict “these are real images” for generated images: this trains the generator to fool the discriminator.\n",
        "\n",
        "Let’s implement it. Like in our VAE example, we’ll use a Model subclass with a custom train_step(). Note that we’ll use two optimizers (one for the generator and one for the discriminator), so we will also override compile() to allow for passing two optimizers.\n",
        "\n",
        "##### The GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KqmOz2pi4d6h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        # Sets up metrics to track the two losses over each training epoch\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Samples random points in the latent space      \n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim))\n",
        "        # Decodes them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "        # Combines them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "        # Assembles labels, discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))],\n",
        "            axis=0\n",
        "        )\n",
        "        # Adds random noise to the labels—an important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Trains the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Samples random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assembles labels that say “these are all real images” (it’s a lie!)\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Trains the generator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(\n",
        "                self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\"d_loss\": self.d_loss_metric.result(),\n",
        "                \"g_loss\": self.g_loss_metric.result()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi3o_Oz5fpZb"
      },
      "source": [
        "Before we start training, let’s also set up a callback to monitor our results: it will use the generator to create and save a number of fake images at the end of each epoch.\n",
        "\n",
        "##### A callback that samples generated images during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KrUu5KusfxDc"
      },
      "outputs": [],
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = keras.utils.array_to_img(generated_images[i])\n",
        "            img.save(f\"generated_img_{epoch:03d}_{i}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9AifSBC7Z08"
      },
      "source": [
        "Finally, we can start training.\n",
        "\n",
        "##### Compiling and training the GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSmpDRzp7dVy"
      },
      "outputs": [],
      "source": [
        "epochs = 100 # You’ll start getting interesting results after epoch 20.\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl5cxS0a7yTJ"
      },
      "source": [
        "When training, you may see the adversarial loss begin to increase considerably, while the discriminative loss tends to zero—the discriminator may end up dominating the generator. If that’s the case, try reducing the discriminator learning rate, and increase the dropout rate of the discriminator. <br>\n",
        "Figure 12.22 shows what our GAN is capable of generating after 30 epochs of training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLWn39IQ74tc"
      },
      "source": [
        "##### Wrapping up\n",
        "- A GAN consists of a generator network coupled with a discriminator network. The discriminator is trained to differentiate between the output of the generator and real images from a training dataset, and the generator is trained to fool the discriminator. Remarkably, the generator never sees images from the training set directly; the information it has about the data comes from the discriminator.\n",
        "- GANs are difficult to train, because training a GAN is a dynamic process rather than a simple gradient descent process with a fixed loss landscape. Getting a GAN to train correctly requires using a number of heuristic tricks, as well as extensive tuning.\n",
        "- GANs can potentially produce highly realistic images. But unlike VAEs, the latent space they learn doesn’t have a neat continuous structure and thus may not be suited for certain practical applications, such as image editing via latent space concept vectors.\n",
        "\n",
        "These few techniques cover only the basics of this fast-expanding field. There’s a lot more to discover out there—generative deep learning is deserving of an entire book of its own."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJVLVmy589Aa"
      },
      "source": [
        "#### Summary\n",
        "- You can use a sequence-to-sequence model to generate sequence data, one step at a time. This is applicable to text generation, but also to note-by-note music generation or any other type of timeseries data.\n",
        "- DeepDream works by maximizing convnet layer activations through gradient ascent in input space.\n",
        "- In the style-transfer algorithm, a content image and a style image are combined together via gradient descent to produce an image with the high-level features of the content image and the local characteristics of the style image.\n",
        "- VAEs and GANs are models that learn a latent space of images and can then dream up entirely new images by sampling from the latent space. Concept vectors in the latent space can even be used for image editing."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ganscolab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f8ee13a16f7ff347d089854b949fd5a4fdba136de942caaffeaf6bff99e7e7f9"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
